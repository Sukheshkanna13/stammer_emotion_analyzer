{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1edQUwwCBzsTyUHIqmiSuFqV9FOmJD-zD","timestamp":1743154725587}],"mount_file_id":"1edQUwwCBzsTyUHIqmiSuFqV9FOmJD-zD","authorship_tag":"ABX9TyP6mPkXe/o76M5E92Yoqtlj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install pydub\n","!pip install SpeechRecognition"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HL8DWjkAxZNm","executionInfo":{"status":"ok","timestamp":1743098801583,"user_tz":-330,"elapsed":8088,"user":{"displayName":"Ilangaviyan U 22MIS1223","userId":"08917255701227525075"}},"outputId":"79692a5e-5ce9-41c8-b73e-9d904592dbaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n","Collecting SpeechRecognition\n","  Downloading speechrecognition-3.14.2-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n","Downloading speechrecognition-3.14.2-py3-none-any.whl (32.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SpeechRecognition\n","Successfully installed SpeechRecognition-3.14.2\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9gtH0bFvvBGn","executionInfo":{"status":"ok","timestamp":1743098698585,"user_tz":-330,"elapsed":96367,"user":{"displayName":"Ilangaviyan U 22MIS1223","userId":"08917255701227525075"}},"outputId":"f94f2726-61fe-4bf0-8b23-60f6fed2d56c"},"outputs":[{"output_type":"stream","name":"stdout","text":["MP3 to WAV conversion completed!\n"]}],"source":["import os\n","import shutil\n","import tempfile\n","import pydub\n","from scipy.io import wavfile\n","\n","# Set paths based on the user's dataset location\n","MP3_AUDIO_DIR = \"/content/drive/MyDrive/metrics_dataset/dataset-stammer/dataset-stammer/\"\n","WAV_AUDIO_DIR = \"/content/drive/MyDrive/metrics_dataset/dataset-stammer/dataset-stammer_wav/\"\n","\n","# Create WAV directory if it doesn't exist\n","os.makedirs(WAV_AUDIO_DIR, exist_ok=True)\n","\n","def read_mp3(file_path):\n","    path, ext = os.path.splitext(file_path)\n","    assert ext == '.mp3', \"File is not an MP3!\"\n","\n","    mp3 = pydub.AudioSegment.from_mp3(file_path)\n","    temp_wav_path = tempfile.mkstemp(suffix=\".wav\")[1]\n","    mp3.export(temp_wav_path, format=\"wav\")\n","    return temp_wav_path\n","\n","# Convert MP3 files to WAV if WAV folder is empty\n","if len(os.listdir(WAV_AUDIO_DIR)) == 0:\n","    for file in os.listdir(MP3_AUDIO_DIR):\n","        if file.endswith(\".mp3\"):\n","            wav_path = read_mp3(os.path.join(MP3_AUDIO_DIR, file))\n","            shutil.move(wav_path, os.path.join(WAV_AUDIO_DIR, file.replace(\".mp3\", \".wav\")))\n","    print(\"MP3 to WAV conversion completed!\")\n","else:\n","    print(\"WAV files already exist, skipping conversion.\")"]},{"cell_type":"code","source":["import os\n","import speech_recognition as sr\n","\n","# Define paths\n","WAV_AUDIO_DIR = \"/content/drive/MyDrive/metrics_dataset/dataset-stammer/dataset-stammer_wav/\"\n","TRANSCRIPT_DIR = \"/content/drive/MyDrive/metrics_dataset/transcriptions/\"\n","\n","# Ensure the transcription directory exists\n","os.makedirs(TRANSCRIPT_DIR, exist_ok=True)\n","\n","def transcribe_audio(file_path):\n","    recognizer = sr.Recognizer()\n","    with sr.AudioFile(file_path) as source:\n","        audio_data = recognizer.record(source)\n","\n","    try:\n","        text = recognizer.recognize_google(audio_data)\n","        return text\n","    except sr.UnknownValueError:\n","        return \"[Unrecognized Speech]\"\n","    except sr.RequestError:\n","        return \"[API Error]\"\n","\n","# Process all WAV files\n","for file in os.listdir(WAV_AUDIO_DIR):\n","    if file.endswith(\".wav\"):\n","        wav_path = os.path.join(WAV_AUDIO_DIR, file)\n","        transcript = transcribe_audio(wav_path)\n","\n","        # Save transcription\n","        transcript_file = os.path.join(TRANSCRIPT_DIR, file.replace(\".wav\", \".txt\"))\n","        with open(transcript_file, \"w\") as f:\n","            f.write(transcript)\n","        print(f\"Transcribed: {file}\")\n","\n","print(\"Transcription process completed!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2pqL3xFyEd3","executionInfo":{"status":"ok","timestamp":1743103193977,"user_tz":-330,"elapsed":4384766,"user":{"displayName":"Ilangaviyan U 22MIS1223","userId":"08917255701227525075"}},"outputId":"48ed545a-dafe-4b3c-e897-1afc4e1e68dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Transcribed: M_0065_18y1m_1.wav\n","Transcribed: M_0394_10y2m_1.wav\n","Transcribed: M_0991_07y6m_1.wav\n","Transcribed: F_0101_10y4m_1.wav\n","Transcribed: M_0815_10y11m_1.wav\n","Transcribed: M_0104_12y9m_1.wav\n","Transcribed: M_0078_16y5m_1.wav\n","Transcribed: M_0090_10y1m_1.wav\n","Transcribed: M_1105_21y0m_1.wav\n","Transcribed: M_0061_14y8m_1.wav\n","Transcribed: M_0096_10y7m_1.wav\n","Transcribed: M_0065_14y5m_1.wav\n","Transcribed: M_0394_08y10m_1.wav\n","Transcribed: M_0121_11y1m_1.wav\n","Transcribed: M_1098_25y0m_1.wav\n","Transcribed: M_0017_09y0m_1.wav\n","Transcribed: M_0052_16y4m_1.wav\n","Transcribed: M_0814_14y5m_1.wav\n","Transcribed: M_0017_09y4m_1.wav\n","Transcribed: M_0081_09y3m_1.wav\n","Transcribed: M_0052_13y1m_1.wav\n","Transcribed: F_0050_10y9m_1.wav\n","Transcribed: F_0811_10y6m_1.wav\n","Transcribed: M_0107_08y5m_1.wav\n","Transcribed: M_0030_17y9m_1.wav\n","Transcribed: F_0811_10y4m_1.wav\n","Transcribed: M_0556_07y8m_1.wav\n","Transcribed: M_0132_12y11m_1.wav\n","Transcribed: M_0553_10y0m_1.wav\n","Transcribed: M_0553_11y0m_1.wav\n","Transcribed: M_0815_10y9m_1.wav\n","Transcribed: M_0128_07y10m_1.wav\n","Transcribed: M_0399_12y4m_1.wav\n","Transcribed: M_1101_35y0m_1.wav\n","Transcribed: M_1102_24y0m_1.wav\n","Transcribed: M_0104_11y2m_1.wav\n","Transcribed: M_0089_05y4m_1.wav\n","Transcribed: M_0061_16y9m-1.wav\n","Transcribed: F_0101_13y1m_1.wav\n","Transcribed: M_0052_12y10m_1.wav\n","Transcribed: M_1107_38y0m_1.wav\n","Transcribed: M_0095_08y10m_1.wav\n","Transcribed: M_0095_07y7m_1.wav\n","Transcribed: M_0821_10y1m_1.wav\n","Transcribed: M_0104_12y1m_1.wav\n","Transcribed: M_0146_10y0m_1.wav\n","Transcribed: M_0098_07y8m_1.wav\n","Transcribed: F_0560_11y7m_1.wav\n","Transcribed: M_0091_11y4m_1.wav\n","Transcribed: M_0124_10y1m_1.wav\n","Transcribed: M_0819_11y11m_1.wav\n","Transcribed: M_0061_15y0m_1.wav\n","Transcribed: M_0100_13y10m_1.wav\n","Transcribed: M_1114_09y10m.1.wav\n","Transcribed: M_0098_10y6m_1.wav\n","Transcribed: M_1103_20y0m_1.wav\n","Transcribed: M_1064_47y0m_1.wav\n","Transcribed: M_0817_10y4m_1.wav\n","Transcribed: M_0210_11y3m_1.wav\n","Transcribed: M_0094_10y6m_1.wav\n","Transcribed: M_0251_15y2m_1.wav\n","Transcribed: M_0126_06y11m_1.wav\n","Transcribed: F_1116_09y6m_1.wav\n","Transcribed: M_0556_08y0m_1.wav\n","Transcribed: M_0104_13y3m_1.wav\n","Transcribed: M_0078_14y4m_1.wav\n","Transcribed: M_0394_09y5m_1.wav\n","Transcribed: M_0138_12y2m_1.wav\n","Transcribed: M_0104_12y7m_1.wav\n","Transcribed: M_0078_12y4m_1.wav\n","Transcribed: M_0133_08y9m_1.wav\n","Transcribed: M_0760_12y3m_1.wav\n","Transcribed: M_0017_08y9m_1.wav\n","Transcribed: M_0028_15y11m_1.wav\n","Transcribed: M_0092_09y11m_1.wav\n","Transcribed: M_0030_12y7m_1.wav\n","Transcribed: M_0030_13y1m_1.wav\n","Transcribed: M_0880_13y4m_1.wav\n","Transcribed: M_0052_12y8m_1.wav\n","Transcribed: M_0107_07y7m_1.wav\n","Transcribed: M_0030_12y1m_1.wav\n","Transcribed: M_0030_12y1m_2.wav\n","Transcribed: M_1017_12y5m_1.wav\n","Transcribed: F_0101_15y2m_1.wav\n","Transcribed: M_1036_09y3m_1.wav\n","Transcribed: M_0087_08y4m_1.wav\n","Transcribed: F_0879_12y5m_1.wav\n","Transcribed: M_0212_11y1m_1.wav\n","Transcribed: F_0558_09y3m_1.wav\n","Transcribed: M_0991_08y4m_1.wav\n","Transcribed: M_0216_12y1m_1.wav\n","Transcribed: M_1106_25y0m_1.wav\n","Transcribed: M_0052_14y4m_1.wav\n","Transcribed: M_0234_09y9m_1.wav\n","Transcribed: M_0100_13y7m_1.wav\n","Transcribed: M_1112_09y9m.1.wav\n","Transcribed: F_0988_12y8m_1.wav\n","Transcribed: M_0061_14y3m_1.wav\n","Transcribed: M_0216_11y6m_1.wav\n","Transcribed: M_0100_12y3m_1.wav\n","Transcribed: M_0213_10y10m_1.wav\n","Transcribed: M_0104_12y8m_1.wav\n","Transcribed: M_1017_11y8m_1.wav\n","Transcribed: F_1039_09y3m_1.wav\n","Transcribed: M_0098_09y8m_1.wav\n","Transcribed: M_0138_13y3m_1.wav\n","Transcribed: F_0558_10y0m_1.wav\n","Transcribed: M_0061_14y9m_1.wav\n","Transcribed: M_0219_14y3m_1.wav\n","Transcribed: M_0078_17y11m_1.wav\n","Transcribed: M_0880_14y6m_1.wav\n","Transcribed: M_0030_19y5m_1.wav\n","Transcribed: M_0102_09y6m_1.wav\n","Transcribed: F_0818_12y4m_1.wav\n","Transcribed: M_0214_09y4m_1.wav\n","Transcribed: M_1104_40y0m_1.wav\n","Transcribed: F_0988_13y6m_1.wav\n","Transcribed: M_0030_12y9m_1.wav\n","Transcribed: M_1100_28y0m_1.wav\n","Transcribed: M_1099_25y0m_1.wav\n","Transcribed: M_0061_14y7m_1.wav\n","Transcribed: M_0061_14y1m_2.wav\n","Transcribed: M_0121_15y1m_1.wav\n","Transcribed: F_0987_12y8m_1.wav\n","Transcribed: M_0394_09y2m_1.wav\n","Transcribed: M_1011_13y10m_1.wav\n","Transcribed: M_0219_11y2m_1.wav\n","Transcribed: M_0077_11y2m_1.wav\n","Transcribed: M_1097_26y0m_1.wav\n","Transcribed: F_0818_14y2m_1.wav\n","Transcribed: M_0112_10y7m_1.wav\n","Transcribed: M_0100_11y2m_1.wav\n","Transcribed: M_0061_18y5m_1.wav\n","Transcribed: M_0217_12y4m_1.wav\n","Transcribed: F_0111_09y6m_1.wav\n","Transcribed: M_0061_14y1m_1.wav\n","Transcribed: M_0030_16y4m_1.wav\n","Transcribed: M_0104_10y3m_1.wav\n","Transcription process completed!\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Define paths\n","TRANSCRIPT_DIR = \"/content/drive/MyDrive/metrics_dataset/transcriptions/\"\n","PROCESSED_DATA_PATH = \"/content/drive/MyDrive/metrics_dataset/processed_data.csv\"\n","\n","# Collect transcription data\n","data = []\n","for file in os.listdir(TRANSCRIPT_DIR):\n","    if file.endswith(\".txt\"):\n","        file_path = os.path.join(TRANSCRIPT_DIR, file)\n","        with open(file_path, \"r\") as f:\n","            transcript = f.read().strip()\n","            data.append({\"filename\": file, \"transcription\": transcript})\n","\n","# Create DataFrame\n","df = pd.DataFrame(data)\n","\n","# Save processed data\n","df.to_csv(PROCESSED_DATA_PATH, index=False)\n","print(f\"Processed data saved to {PROCESSED_DATA_PATH}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPnunge8DDSk","executionInfo":{"status":"ok","timestamp":1743103216822,"user_tz":-330,"elapsed":1999,"user":{"displayName":"Ilangaviyan U 22MIS1223","userId":"08917255701227525075"}},"outputId":"a406de4e-d55d-4886-c475-fdde636e0ffe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processed data saved to /content/drive/MyDrive/metrics_dataset/processed_data.csv\n"]}]},{"cell_type":"code","source":["import re\n","\n","# Define paths\n","PROCESSED_DATA_PATH = \"/content/drive/MyDrive/metrics_dataset/processed_data.csv\"\n","STUTTER_ANALYSIS_PATH = \"/content/drive/MyDrive/metrics_dataset/stutter_analysis.csv\"\n","\n","# Load processed data\n","df = pd.read_csv(PROCESSED_DATA_PATH)\n","\n","# Define stuttering patterns (e.g., repeated words, fillers)\n","def detect_stutter(text):\n","    repeated_words = re.findall(r'\\b(\\w+) \\1\\b', text)\n","    fillers = re.findall(r'\\b(um|uh|like|you know)\\b', text, re.IGNORECASE)\n","\n","    return len(repeated_words) + len(fillers)\n","\n","# Apply stuttering detection\n","df[\"stutter_count\"] = df[\"transcription\"].apply(detect_stutter)\n","\n","# Save results\n","df.to_csv(STUTTER_ANALYSIS_PATH, index=False)\n","print(f\"Stutter analysis saved to {STUTTER_ANALYSIS_PATH}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_J3mK8R0DRMm","executionInfo":{"status":"ok","timestamp":1743103289494,"user_tz":-330,"elapsed":53,"user":{"displayName":"Ilangaviyan U 22MIS1223","userId":"08917255701227525075"}},"outputId":"16abd3e0-dcd9-47b6-ba46-f49fedef7ed3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Stutter analysis saved to /content/drive/MyDrive/metrics_dataset/stutter_analysis.csv\n"]}]},{"cell_type":"code","source":["from textblob import TextBlob\n","\n","# Define paths\n","STUTTER_ANALYSIS_PATH = \"/content/drive/MyDrive/metrics_dataset/stutter_analysis.csv\"\n","SPEECH_ANALYSIS_PATH = \"/content/drive/MyDrive/metrics_dataset/speech_analysis.csv\"\n","\n","# Load stutter analysis data\n","df = pd.read_csv(STUTTER_ANALYSIS_PATH)\n","\n","# Perform sentiment analysis on transcriptions\n","def analyze_sentiment(text):\n","    blob = TextBlob(text)\n","    return blob.sentiment.polarity\n","\n","df[\"sentiment_score\"] = df[\"transcription\"].apply(analyze_sentiment)\n","\n","# Save results\n","df.to_csv(SPEECH_ANALYSIS_PATH, index=False)\n","print(f\"Speech analysis saved to {SPEECH_ANALYSIS_PATH}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ECbYjPSuDdkW","executionInfo":{"status":"ok","timestamp":1743103324172,"user_tz":-330,"elapsed":2595,"user":{"displayName":"Ilangaviyan U 22MIS1223","userId":"08917255701227525075"}},"outputId":"e600001f-84ad-4067-999d-d08776e5ee9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Speech analysis saved to /content/drive/MyDrive/metrics_dataset/speech_analysis.csv\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a1xygquEny52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import librosa\n","import numpy as np\n","import pandas as pd\n","import os\n","\n","# Define paths\n","WAV_AUDIO_DIR = \"/content/drive/MyDrive/metrics_dataset/dataset-stammer/dataset-stammer_wav/\"\n","EMOTION_ANALYSIS_PATH = \"/content/drive/MyDrive/metrics_dataset/emotion_analysis.csv\"\n","\n","# Load Google's YAMNet model from TensorFlow Hub\n","yamnet_model_handle = \"https://tfhub.dev/google/yamnet/1\"\n","yamnet = hub.load(yamnet_model_handle)\n","\n","# Emotion labels (mapping from AudioSet class labels)\n","emotion_labels = [\"neutral\", \"calm\", \"happy\", \"sad\", \"angry\", \"fearful\", \"disgust\", \"surprised\"]\n","\n","# Function to extract features and classify emotion\n","def predict_emotion(audio_path):\n","    try:\n","        # Load and process audio\n","        waveform, sr = librosa.load(audio_path, sr=16000)\n","        waveform = waveform[:sr * 10]  # Limit to 10 seconds\n","\n","        if waveform.shape[0] == 0:\n","            return \"unknown\"  # If no valid audio, return \"unknown\"\n","\n","        # Ensure waveform is 1D (YAMNet expects shape (None,))\n","        waveform = np.squeeze(waveform)\n","\n","        # Run YAMNet model\n","        scores, embeddings, spectrogram = yamnet(waveform)\n","\n","        # Simple classification: Take the top prediction\n","        predicted_class = int(np.argmax(scores.numpy()))  # Ensure it's an integer\n","        return emotion_labels[predicted_class % len(emotion_labels)]\n","\n","    except Exception as e:\n","        print(f\"Error processing {audio_path}: {e}\")\n","        return \"error\"\n","\n","# Process all WAV files\n","data = []\n","for file in os.listdir(WAV_AUDIO_DIR):\n","    if file.endswith(\".wav\"):\n","        wav_path = os.path.join(WAV_AUDIO_DIR, file)\n","        emotion = predict_emotion(wav_path)\n","        data.append({\"filename\": file, \"emotion\": emotion})\n","\n","# Save results\n","df = pd.DataFrame(data)\n","df.to_csv(EMOTION_ANALYSIS_PATH, index=False)\n","print(f\"Emotion analysis saved to {EMOTION_ANALYSIS_PATH}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJZFnXy-EnOv","executionInfo":{"status":"ok","timestamp":1743113104338,"user_tz":-330,"elapsed":44786,"user":{"displayName":"Ilangaviyan U 22MIS1223","userId":"08917255701227525075"}},"outputId":"d3f9dc66-f0f3-4799-fa87-4c6c2a8b088e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Emotion analysis saved to /content/drive/MyDrive/metrics_dataset/emotion_analysis.csv\n"]}]}]}